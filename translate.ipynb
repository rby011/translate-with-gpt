{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['dst_lang', 'src_lang'] messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['dst_lang', 'src_lang'], template='<task>\\ntranslate {src_lang} into {dst_lang} considering the below : \\n\\n1. make three different (but same meaning, same tone, same style) sentences per a {src_lang} sentence\\n2. translated sentence should be accurate, natural,fluent, contextual-consistent, factual-consistent, cutural-appropriate,  \\n3. give me your ouput as a json object \\n4. give me only the json object\\n</task>\\n\\n<input example>\\n{{\\n\\t\"src\" : [\"sample given {src_lang} sentence#1\" , \"sample given {src_lang} sentence#2\"]\\n}}\\n</input example>\\n\\n<output example>\\n{{\\n\\t\"dst\":[\\n\\t\\t[sample transted {dst_lang} sentence for #1\", \"sample translated {dst_lang} sentence for #1\", \"sample translated {dst_lang} sentence for #1\"],\\n\\t\\t[sample transted {dst_lang} sentence for #2\", \"sample translated {dst_lang} sentence for #2\", \"sample translated {dst_lang} sentence for #2\"]\\n\\t]\\n\\n}}\\n</output example>')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='{{\"src\": [\"Feeling hungry, we grabbed a pizza from the fridge and microwaved it.\", \"The video chronologically shows the son\\'s finger stuck in a hole of the dog house, the rescue process by paramedics, and the conclusion of the entire incident.\"]}}'))]\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: <task>\n",
      "translate english into korean considering the below : \n",
      "\n",
      "1. make three different (but same meaning, same tone, same style) sentences per a english sentence\n",
      "2. translated sentence should be accurate, natural,fluent, contextual-consistent, factual-consistent, cutural-appropriate,  \n",
      "3. give me your ouput as a json object \n",
      "4. give me only the json object\n",
      "</task>\n",
      "\n",
      "<input example>\n",
      "{\n",
      "\t\"src\" : [\"sample given english sentence#1\" , \"sample given english sentence#2\"]\n",
      "}\n",
      "</input example>\n",
      "\n",
      "<output example>\n",
      "{\n",
      "\t\"dst\":[\n",
      "\t\t[sample transted korean sentence for #1\", \"sample translated korean sentence for #1\", \"sample translated korean sentence for #1\"],\n",
      "\t\t[sample transted korean sentence for #2\", \"sample translated korean sentence for #2\", \"sample translated korean sentence for #2\"]\n",
      "\t]\n",
      "\n",
      "}\n",
      "</output example>\n",
      "Human: {\"src\": [\"Feeling hungry, we grabbed a pizza from the fridge and microwaved it.\", \"The video chronologically shows the son's finger stuck in a hole of the dog house, the rescue process by paramedics, and the conclusion of the entire incident.\"]}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "# Raw : \n",
      "{'dst_lang': 'korean',\n",
      " 'output': '{\\n'\n",
      "           '\\t\"dst\":[\\n'\n",
      "           '\\t\\t[\"배가 고파서, 우리는 냉장고에서 피자를 꺼내서 전자렌지에 돌렸습니다.\", \"배가 고프니까, 냉장고에서 피자를 '\n",
      "           '가져와서 전자렌지에 데웠습니다.\", \"배가 고파서, 냉장고에 있는 피자를 꺼내서 전자렌지로 데웠습니다.\"],\\n'\n",
      "           '\\t\\t[\"이 비디오는 아들의 손가락이 개집 구멍에 끼어버린 것부터 응급구조대의 구조 과정, 그리고 전체 사건의 '\n",
      "           '결말까지를 시간 순서대로 보여줍니다.\", \"이 비디오는 아들의 손가락이 개집의 구멍에 갇힌 것부터 구조대의 구조 과정, '\n",
      "           '그리고 사건의 마무리까지를 시간 순서대로 보여줍니다.\", \"이 비디오는 아들의 손가락이 개집의 구멍에 끼어버린 것부터 '\n",
      "           '응급구조대에 의한 구조 과정, 그리고 전체 사건의 종결까지를 시간 순서대로 보여줍니다.\"]\\n'\n",
      "           '\\t]\\n'\n",
      "           '}',\n",
      " 'src_lang': 'english'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.schema import BaseOutputParser\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "from typing import List\n",
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "def read_prompt_template(file_path: str) -> str:\n",
    "    with open(file_path, \"r\") as f:\n",
    "        prompt_template = f.read()\n",
    "    return prompt_template\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    load_dotenv()\n",
    "        \n",
    "    llm = ChatOpenAI(temperature=0.1, \n",
    "                     max_tokens=500, \n",
    "                     model=\"gpt-4\",\n",
    "                     verbose = True)\n",
    "        \n",
    "    # prompt_template = ChatPromptTemplate.from_template(\n",
    "    #     template=read_prompt_template('prompts/1. translate.txt')\n",
    "    # )\n",
    "    src = {}\n",
    "    src[\"src\"] = [\"Feeling hungry, we grabbed a pizza from the fridge and microwaved it.\", \n",
    "                  \"The video chronologically shows the son's finger stuck in a hole of the dog house, the rescue process by paramedics, and the conclusion of the entire incident.\"]\n",
    "    \n",
    "    prompt_template = ChatPromptTemplate.from_messages( [\n",
    "        (\"system\", read_prompt_template('prompts/1. translate.txt')),\n",
    "        (\"human\", json.dumps(src).replace('{','{{').replace('}','}}')),\n",
    "        ] )\n",
    "\n",
    "    print(prompt_template)\n",
    "\n",
    "    # CHAINING\n",
    "    chain = LLMChain(\n",
    "        llm = llm, \n",
    "        prompt = prompt_template, \n",
    "        output_key = \"output\",\n",
    "        verbose = True\n",
    "    )\n",
    "    \n",
    "    # make prompt with template\n",
    "    req = {}\n",
    "    req['src_lang'] = 'english'\n",
    "    req['dst_lang'] = 'korean'\n",
    "    \n",
    "    \n",
    "    # request \n",
    "    result = chain(req)\n",
    "\n",
    "    # check response\n",
    "    print(\"# Raw : \")\n",
    "    pprint(result)\n",
    "\n",
    "    \n",
    "    dst = json.loads(result['output'])['dst']\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2 3 3\n"
     ]
    }
   ],
   "source": [
    "dst = json.loads(result['output'])['dst']\n",
    "\n",
    "print(len(src['src']) , len(dst) , len(dst[0]), len(dst[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"src\": [\"Feeling hungry, we grabbed a pizza from the fridge and microwaved it.\", \"The video chronologically shows the son\\'s finger stuck in a hole of the dog house, the rescue process by paramedics, and the conclusion of the entire incident.\"]}'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(src) # serializa object to json formatted string\n",
    "\n",
    "# json.loads # deserialize json formatted strint to python object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.load"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
